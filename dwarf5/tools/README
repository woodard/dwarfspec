These tools are intended to help updating the latex
source of a DWARF document to get its references
complete and correct.

CAUTION: 
The tools don't really do parsing and
the lexical processing is barely adequate for the task.

They don't understand the % means 'comment', so avoid
comments containing latex code or anything like latex.

The tools are not necessarily equivalent in what
details of input they accept.   For example, 
Some will handle  \livelink{chap:DWTAGfoo}{  DW\_TAG\_foo  }
(notice the spaces around the DW\_TAG\_foo) and some won't.
So use \livelink{chap:DWTAGfoo}{DW\_TAG\_foo} instead with
no pointless spaces (or newlines). Then you won't be disappointed.

The tools assume you use \livelink and other local commands.
If you use the native latex equivalent the tools won't understand.


The requirement of the \ before _ in latex is annoying.
You can avoid work typing that cruft by just typeing
DW_TAG_foo  and running  tohyphen.py on the text, which will
turn it into   DW\-\_TAG\-\_foo which is what you want.
The hyphens result in nicely formatted lines with line breaks in
the DW_* strings, at
least in some contexts (but not always).


Various character (% - and more) have special meaning to latex.
So just typing them and expecting them to appear in the generated
document is going to result in disappointment.  See the use
of \dash in the document.


Our fundamental approach is to tokenize the input line-by-line
and then use trivial pattern matching to determine what
tokens need updating on what lines.  Always trying to ensure
that unless we intend to change a line that it is emitted
byte-for-byte unchanged.  We change lines (in most cases)
by simply inserting new tokens on the line (or possibly
inserting characters into a token).

Because latex names are non-traditional (compared to
other languages) we adopt an inefficient but
simple scanning and lexing approach.

BORING DETAILS (you can ignore what follows):
Every latex source file is read completely into an dwfile object 
which contains a 
List of lines
   each line composed of a list of tokens
       each token described below.

If we are writing out updated latex source we want all the
unchanged text output to match the input.  No spacing changes
and no changes except what the task at hand is to do.
So the tokens serve that task.

For example, one task at hand might be to find every DW_*
reference and ensure it is either a link target (livetarg) or a
link (livelink), and rewrite any that are neither as a link.
(see our latex commands livelink and livetarg in latex source).


Another task at hand might be to take every DW_ and rewrite
things like  DW\_AT\_foo as DW\-\_AT\-\_foo  so that latex
can hyphenate.

Sometimes we'll want to read a single latex file, sometimes several of them.
 
If we're reading all the files at once (for some reason) we construct
an overall 
   List of LFile (LFile mentioned above).


TOKENS:
This part is idiosyncratic to reflect our other goals.

INDIVIDUAL TOKEN characters:
{
}
[
]
space-character
tab-character
are individual tokens.
All 4 forms (tex, underbar, std, label) are identical.

The space or tab character is an individual token.
All 4 forms (tex, underbar, std, label) are identical.

We swallow the input linefeed (or CR-LF) on input,
it does not appear in the tokens.

IDENTIFIER:
The letters in \-_A-Za-z0-9 allowed in an identifier.
An identifier begins with one of _ \ letter and has
at least one letter in it.
Identifers are held in multiple strings in a token
        tex:   (meaning with \_ and possibly \-)
        underbar:  (meaning with \_, no \-)
        std:   (meaning with _ no \, as in the DWARF std)  
        label: (meaning with no _ or \ the form used as part of labels )

OTHER:
All other characters are considered letters which are
to be reproduced on output.  A glob of such are simply considered
a non-identifier single token. 
All 4 forms (tex, underbar, std, label) are identical.


Performance:
We simply don't care about performance as long as a task takes
less than a few minutes. There are only about 70,000 words in a complete
document so we ignore efficiency issues.
